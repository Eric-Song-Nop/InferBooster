{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "First, we enable the cluster to scale up. Note that if you run an auto-scaling cluster,\n",
    "Google will suspend your nodes. Make sure to have the experiment prepared before running the commands.\n",
    "\n",
    "The following is assumed ready:\n",
    "* GKE/Kubernetes cluster (see also `terraform/terraform_notebook.ipynb`)\n",
    "    * 2 nodes pools (default for system & dependencies, experiment pool)\n",
    "* Docker image (including dataset, to speed-up starting experiments).\n",
    "    * Within a bash shell\n",
    "        * Make sure to have the `requirements-cpu.txt` installed (or `requirements-gpu.txt (in a virtual venv/conda environment). You can run `pip3 install -r requirements-cpu.txt`\n",
    "    * First run the extractor (locally) `python3 -m fltk extractor configs/example_cloud_experiment.json`\n",
    "        *  This downloads datasets to be included in the docker image.\n",
    "    * Build the container `DOCKER_BUILDKIT=1 docker build --platform linux/amd64 . --tag gcr.io/$PROJECT_ID/fltk`\n",
    "    * Push to your gcr.io repository `docker push gcr.io/$PROJECT_ID/fltk`\n",
    "\n",
    "\n",
    "With that setup, first set some variables used throughout the experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for fltk-testbed-cluster.\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "### CHANGE ME! ###\n",
    "##################\n",
    "PROJECT_ID=\"eminent-parsec-362007\"\n",
    "CLUSTER_NAME=\"fltk-testbed-cluster\"\n",
    "DEFAULT_POOL=\"default-node-pool\"\n",
    "EXPERIMENT_POOL=\"medium-fltk-pool-1\"\n",
    "REGION=\"us-central1-c\"\n",
    "# alias gcloud=/home/yifan/.local/tools/google-cloud-sdk/bin/gcloud\n",
    "\n",
    "# In case we do not yet have the credentials/kubeconfig\n",
    "gcloud container clusters get-credentials $CLUSTER_NAME --region $REGION --project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the default-node-pool up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing fltk-testbed-cluster...done.                                          \n",
      "Updated [https://container.googleapis.com/v1/projects/eminent-parsec-362007/zones/us-central1-c/clusters/fltk-testbed-cluster].\n"
     ]
    }
   ],
   "source": [
    "# These commands might take a while to complete.\n",
    "gcloud container clusters resize $CLUSTER_NAME --node-pool $DEFAULT_POOL \\\n",
    "     --num-nodes 1 --region $REGION --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "In case you have already tested something or ran another experiment, we have to remove the deployment of the Orchestrator. This will not delete any experiment data, as this persists on one of the ReadWriteMany PVCs.\n",
    "\n",
    "\n",
    "Currently, the Orchestrator is deployed using a `Deployment` definition, a future version will replace this with a `Deployment` definition, to make this step unnecessary. For experiments this means the following:\n",
    "\n",
    "1. A single deployment can exist at a single time in a single namespace. This includes 'completed' experiments.\n",
    "2. For running batches of experiments, a BatchOrchestrator is provided.\n",
    "\n",
    "\n",
    "ℹ️ This will not remove any data, but if your orchestrator is still/already running experiments, this will stop the deployment. Running training jobs will not be stopped, for this you can use `kubectl`. ConfigMaps created by the Orchestrator (to provide experiment configurations), will not be removed. See the commented code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 01:35:10.723238   31288 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.25+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "Error: uninstall: Release not loaded: flearner: release: not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# If you want to delete all pytorch trainjobs, uncomment the command below.\n",
    "# kubectl delete pytorchjobs.kubeflow.org --all --namespace test\n",
    "\n",
    "# If you want to delete all existing configuration map objects in a namespace, run teh command below\n",
    "# kubectl delete configmaps --all --namespace test\n",
    "\n",
    "helm uninstall -n test flearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install extractor\n",
    "\n",
    "Deploy the TensorBoard service and persistent volumes, required for deployment of the orchestrator's chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 01:37:13.185099   31914 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.25+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "Release \"extractor\" has been upgraded. Happy Helming!\n",
      "NAME: extractor\n",
      "LAST DEPLOYED: Sat Oct  8 01:37:17 2022\n",
      "NAMESPACE: test\n",
      "STATUS: deployed\n",
      "REVISION: 2\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "Get the FLTK extractors Tensorboard URL by running:\n",
      "\n",
      "export POD_NAME=$(kubectl get pods -n test -l \"app.kubernetes.io/name=fltk.extractor\" -o jsonpath=\"{.items[0].metadata.name}\")\n",
      "echo http://localhost:6006/\n",
      "kubectl -n test port-forward $POD_NAME 6006:6006\n"
     ]
    }
   ],
   "source": [
    "helm upgrade --install -n test extractor ../charts/extractor -f ../charts/fltk-values.yaml \\\n",
    "    --set provider.projectName=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define experiment configuration files\n",
    "\n",
    "Deployment of experiments is currently done through a Helm Deployment. A future release (™️) will rework this to a Job definition, as this allows to re-use the template more easily.\n",
    "\n",
    "\n",
    "> The `EXPERIMENT_FILE` will contain the description of the experiments\n",
    "> The `CLUSTER_CONFIG` will contain shared configurations for logging, Orchestrator configuration and replication information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_FILE=\"../configs/distributed_tasks/example_arrival_config.json\"\n",
    "CLUSTER_CONFIG=\"../configs/example_cloud_experiment.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup experiment variables\n",
    "Next, we will deploy the experiments.\n",
    "\n",
    "\n",
    "We provide a configuration file, `charts/fltk-values.yaml`, in here change the values under the `provider` block. Change `projectName` to your Google Cloud Project ID.\n",
    "\n",
    "```yaml\n",
    "provider:\n",
    "    domain: gcr.io\n",
    "    projectName: CHANGE_ME!\n",
    "    imageName: fltk:latest\n",
    "```\n",
    "\n",
    "We use the `--set-file` flag for `helm`, as currently, Helm does not support using files outside of the chart root directory (in this case `charts/orchestrator`). Using `--set-file` we can dynamically provide these files. See also issue [here](https://github.com/helm/helm/issues/3276)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../configs/distributed_tasks/example_arrival_config.json\n",
      "../configs/example_cloud_experiment.json\n",
      "eminent-parsec-362007\n"
     ]
    }
   ],
   "source": [
    "echo $EXPERIMENT_FILE\n",
    "echo $CLUSTER_CONFIG\n",
    "echo $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 01:39:06.908151   32453 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.25+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "Error: uninstall: Release not loaded: experiment-orchestrator: release: not found\n",
      "W1008 01:39:07.630393   32457 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.25+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "NAME: experiment-orchestrator\n",
      "LAST DEPLOYED: Sat Oct  8 01:39:11 2022\n",
      "NAMESPACE: test\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "You successfully launched an experiment configuration on your cluster in test.\n",
      "\n",
      "N.B. Make sure to collect all data after completing your experiment!\n",
      "N.B. Re-installing the orchestrator WILL RESULT IN DELETION OF ALL TRAINJOBS and PODS!\n"
     ]
    }
   ],
   "source": [
    "helm uninstall -n test experiment-orchestrator\n",
    "helm install -n test experiment-orchestrator ../charts/orchestrator -f ../charts/fltk-values.yaml \\\n",
    "    --set-file orchestrator.experiment=$EXPERIMENT_FILE,orchestrator.configuration=$CLUSTER_CONFIG \\\n",
    "    --set provider.projectName=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 01:46:47.410367   34508 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "NAME                                                         READY   STATUS    RESTARTS   AGE\n",
      "pod/fl-extractor-7b79f57d98-tt8dz                            1/1     Running   0          14m\n",
      "pod/fl-server                                                1/1     Running   0          7m34s\n",
      "pod/nfs-server-nfs-server-provisioner-0                      1/1     Running   0          37m\n",
      "pod/trainjob-33346b1e-e8b4-437f-a2fb-ee2042d4980f-master-0   1/1     Running   0          60s\n",
      "pod/trainjob-33346b1e-e8b4-437f-a2fb-ee2042d4980f-worker-0   1/1     Running   0          60s\n",
      "pod/trainjob-33784eca-66f8-4821-aa27-6c35a401e005-master-0   1/1     Running   0          4m\n",
      "pod/trainjob-33784eca-66f8-4821-aa27-6c35a401e005-worker-0   1/1     Running   0          4m\n",
      "pod/trainjob-366bc88b-f62c-470b-9dd2-d7b272b1398e-master-0   1/1     Running   0          4m10s\n",
      "pod/trainjob-366bc88b-f62c-470b-9dd2-d7b272b1398e-worker-0   1/1     Running   0          4m10s\n",
      "pod/trainjob-916ed6ec-1529-4396-b091-197133f02692-master-0   1/1     Running   0          4m20s\n",
      "pod/trainjob-916ed6ec-1529-4396-b091-197133f02692-worker-0   1/1     Running   0          4m20s\n",
      "pod/trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-master-0   1/1     Running   0          4m30s\n",
      "pod/trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-worker-0   1/1     Running   0          4m30s\n",
      "\n",
      "NAME                                                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                                                     AGE\n",
      "service/nfs-server-nfs-server-provisioner                        ClusterIP   192.168.74.87   <none>        2049/TCP,2049/UDP,32803/TCP,32803/UDP,20048/TCP,20048/UDP,875/TCP,875/UDP,111/TCP,111/UDP,662/TCP,662/UDP   37m\n",
      "service/trainjob-33346b1e-e8b4-437f-a2fb-ee2042d4980f-master-0   ClusterIP   None            <none>        23456/TCP                                                                                                   61s\n",
      "service/trainjob-33346b1e-e8b4-437f-a2fb-ee2042d4980f-worker-0   ClusterIP   None            <none>        23456/TCP                                                                                                   61s\n",
      "service/trainjob-33784eca-66f8-4821-aa27-6c35a401e005-master-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m1s\n",
      "service/trainjob-33784eca-66f8-4821-aa27-6c35a401e005-worker-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m1s\n",
      "service/trainjob-366bc88b-f62c-470b-9dd2-d7b272b1398e-master-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m11s\n",
      "service/trainjob-366bc88b-f62c-470b-9dd2-d7b272b1398e-worker-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m11s\n",
      "service/trainjob-916ed6ec-1529-4396-b091-197133f02692-master-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m21s\n",
      "service/trainjob-916ed6ec-1529-4396-b091-197133f02692-worker-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m21s\n",
      "service/trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-master-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m31s\n",
      "service/trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-worker-0   ClusterIP   None            <none>        23456/TCP                                                                                                   4m31s\n",
      "\n",
      "NAME                           READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "deployment.apps/fl-extractor   1/1     1            1           14m\n",
      "\n",
      "NAME                                      DESIRED   CURRENT   READY   AGE\n",
      "replicaset.apps/fl-extractor-7b79f57d98   1         1         1       14m\n",
      "\n",
      "NAME                                                 READY   AGE\n",
      "statefulset.apps/nfs-server-nfs-server-provisioner   1/1     37m\n"
     ]
    }
   ],
   "source": [
    "kubectl get all -n test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1007 12:01:40.470686    8441 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.25+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "NAME                   \tNAMESPACE\tREVISION\tUPDATED                                 \tSTATUS  \tCHART                         \tAPP VERSION\n",
      "experiment-orchestrator\ttest     \t1       \t2022-10-07 12:01:28.660963903 +0200 CEST\tdeployed\t../docker-compose-gcloud-0.3.0\t1.17.0     \n",
      "extractor              \ttest     \t5       \t2022-10-07 12:01:16.723639247 +0200 CEST\tdeployed\tfltk-extractor-0.1.0          \t1.17.0     \n",
      "nfs-server             \ttest     \t1       \t2022-10-05 16:05:30.825424619 +0200 CEST\tdeployed\tnfs-server-provisioner-1.1.3  \t2.3.0      \n"
     ]
    }
   ],
   "source": [
    "helm ls -n=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 01:45:11.093942   34089 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "10-07-2022 23:39:26 root         INFO     Loading file config/configuration.fltk.json\n",
      "No argument path is provided.\n",
      "10-07-2022 23:39:26 root         INFO     Starting in cluster mode.\n",
      "10-07-2022 23:39:26 root         INFO     Starting with experiment replication: 0 with seed: 42\n",
      "10-07-2022 23:39:26 root         INFO     Starting as Orchestrator\n",
      "10-07-2022 23:39:26 root         INFO     Starting Orchestrator, initializing resources....\n",
      "10-07-2022 23:39:26 root         INFO     Loading in cluster configuration file\n",
      "10-07-2022 23:39:26 root         INFO     Pointing configuration to in cluster configuration.\n",
      "10-07-2022 23:39:26 root         INFO     Starting cluster manager\n",
      "10-07-2022 23:39:26 ClusterManager INFO     Spinning up cluster manager...\n",
      "10-07-2022 23:39:26 ResourceWatchDog INFO     Starting resource watchdog\n",
      "10-07-2022 23:39:26 ResourceWatchDog INFO     Fetching node information of cluster...\n",
      "10-07-2022 23:39:26 root         INFO     Starting arrival generator\n",
      "10-07-2022 23:39:26 root         INFO     Starting orchestrator\n",
      "10-07-2022 23:39:26 SimulatedArrivalGenerator INFO     Starting execution of arrival generator.\n",
      "10-07-2022 23:39:26 SimulatedArrivalGenerator INFO     Populating tick lists with initial arrivals\n",
      "10-07-2022 23:39:26 SimulatedArrivalGenerator INFO     Creating task for train_job_0\n",
      "10-07-2022 23:39:26 SimulatedArrivalGenerator INFO     Arrival Arrival(ticks=180, task=TrainTask(network_configuration=NetworkConfiguration(network=<Nets.fashion_mnist_cnn: 'FashionMNISTCNN'>, dataset=<Dataset.mnist: 'mnist'>, loss_function=<Loss.cross_entropy_loss: 'CrossEntropyLoss'>), system_parameters=SystemParameters(data_parallelism=2, configurations=OrderedDict([('default', SystemResources(cores='500m', memory='1Gi'))])), hyper_parameters=HyperParameters(default=HyperParameterConfiguration(optimizer_config=OptimizerConfig(type=<Optimizations.adam: 'Adam'>, momentum=None, betas=[0.9, 0.999], lr=0.001), scheduler_config=SchedulerConfig(scheduler_step_size=50, scheduler_gamma=0.5, min_lr=1e-10), bs=128, test_bs=128, lr_decay=0.0002, total_epochs=100), configurations=OrderedDict([('Master', HyperParameterConfiguration(optimizer_config=OptimizerConfig(type=<Optimizations.adam: 'Adam'>, momentum=None, betas=[0.9, 0.999], lr=0.001), scheduler_config=SchedulerConfig(scheduler_step_size=50, scheduler_gamma=0.5, min_lr=1e-10), bs=128, test_bs=128, lr_decay=0.0002, total_epochs=100)), ('Worker', HyperParameterConfiguration(optimizer_config=OptimizerConfig(type=<Optimizations.adam: 'Adam'>, momentum=None, betas=[0.9, 0.999], lr=0.001), scheduler_config=SchedulerConfig(scheduler_step_size=50, scheduler_gamma=0.5, min_lr=1e-10), bs=128, test_bs=128, lr_decay=0.0002, total_epochs=100))])), learning_parameters=LearningParameters(cuda=False, rounds=None, epochs_per_round=None, clients_per_round=None, aggregation=None, data_sampler=None), seed=None, identifier='train_job_0', replication=None, priority=1, experiment_type=<ExperimentType.DISTRIBUTED: 'distributed'>), task_id='train_job_0') arrives at 180 seconds\n",
      "10-07-2022 23:39:26 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:39:27 ResourceWatchDog INFO     Starting with watching resources\n",
      "10-07-2022 23:39:31 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:39:36 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:39:37 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:39:41 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:39:46 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:39:47 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:39:51 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:39:56 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:39:57 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:40:01 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:06 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:07 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:40:11 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:16 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:18 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:40:21 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:26 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:28 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:40:28 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:40:31 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:36 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:38 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:40:41 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:46 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:49 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:40:51 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:56 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:40:59 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:41:01 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:06 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:09 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:41:11 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:16 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:20 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:41:21 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:26 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:30 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:41:30 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:41:31 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:36 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:40 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:41:41 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:46 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:50 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:41:51 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:41:56 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:01 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:42:01 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:06 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:11 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:42:11 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:16 SimulatedArrivalGenerator INFO     Creating task for train_job_0\n",
      "10-07-2022 23:42:16 SimulatedArrivalGenerator INFO     Arrival train_job_0 arrives in 0 seconds\n",
      "10-07-2022 23:42:16 Orchestrator INFO     Scheduling arrival of Arrival: 9afc7e4d-e38a-4f8d-88f4-3d38727842f1\n",
      "10-07-2022 23:42:17 Orchestrator INFO     Deploying on cluster: 9afc7e4d-e38a-4f8d-88f4-3d38727842f1\n",
      "10-07-2022 23:42:17 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:21 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:42:22 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:26 SimulatedArrivalGenerator INFO     Creating task for train_job_0\n",
      "10-07-2022 23:42:26 SimulatedArrivalGenerator INFO     Arrival train_job_0 arrives in 0 seconds\n",
      "10-07-2022 23:42:27 Orchestrator INFO     Scheduling arrival of Arrival: 916ed6ec-1529-4396-b091-197133f02692\n",
      "10-07-2022 23:42:27 Orchestrator INFO     Deploying on cluster: 916ed6ec-1529-4396-b091-197133f02692\n",
      "10-07-2022 23:42:27 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:32 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:42:32 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:32 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:42:36 SimulatedArrivalGenerator INFO     Creating task for train_job_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-07-2022 23:42:36 SimulatedArrivalGenerator INFO     Arrival train_job_0 arrives in 0 seconds\n",
      "10-07-2022 23:42:37 Orchestrator INFO     Scheduling arrival of Arrival: 366bc88b-f62c-470b-9dd2-d7b272b1398e\n",
      "10-07-2022 23:42:37 Orchestrator INFO     Deploying on cluster: 366bc88b-f62c-470b-9dd2-d7b272b1398e\n",
      "10-07-2022 23:42:37 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:42 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:42 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:42:46 SimulatedArrivalGenerator INFO     Creating task for train_job_0\n",
      "10-07-2022 23:42:46 SimulatedArrivalGenerator INFO     Arrival train_job_0 arrives in 180 seconds\n",
      "10-07-2022 23:42:47 Orchestrator INFO     Scheduling arrival of Arrival: 33784eca-66f8-4821-aa27-6c35a401e005\n",
      "10-07-2022 23:42:47 Orchestrator INFO     Deploying on cluster: 33784eca-66f8-4821-aa27-6c35a401e005\n",
      "10-07-2022 23:42:47 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:52 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:42:52 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:42:57 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:02 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:03 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:43:07 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:12 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:13 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:43:17 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:22 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:23 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:43:27 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:32 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:33 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:43:34 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:43:37 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:42 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:44 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:43:47 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:52 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:43:54 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:43:57 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:02 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:05 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:44:07 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:12 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:15 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:44:17 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:22 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:25 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:44:27 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:32 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:35 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:44:36 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:44:37 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:42 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:46 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:44:47 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:52 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:44:56 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:44:57 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:45:02 Orchestrator INFO     Still alive...\n",
      "10-07-2022 23:45:07 ResourceWatchDog INFO     Fetching pod information of cluster...\n",
      "10-07-2022 23:45:07 Orchestrator INFO     Still alive...\n"
     ]
    }
   ],
   "source": [
    "# To get logs from the orchestrator\n",
    "kubectl logs -n test fl-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 01:47:35.389867   34721 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "Defaulted container \"pytorch\" out of: pytorch, init-pytorch (init)\n",
      "10-07-2022 23:44:32 root         INFO     Loading file config/configuration.fltk.json\n",
      "10-07-2022 23:44:32 root         INFO     Starting in client mode\n",
      "10-07-2022 23:44:32 root         INFO     Starting with host=trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-master-0 and port=23456\n",
      "10-07-2022 23:44:32 root         INFO     Initializing backend for training process: gloo\n",
      "10-07-2022 23:44:32 torch.distributed.distributed_c10d INFO     Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "10-07-2022 23:44:32 torch.distributed.distributed_c10d INFO     Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "10-07-2022 23:44:32 root         INFO     Starting Creating client with 1\n",
      "10-07-2022 23:44:32 Client-1-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     Initializing learning client\n",
      "10-07-2022 23:44:32 root         INFO     Getting net: Nets.fashion_mnist_cnn\n",
      "10-07-2022 23:44:32 Client-1-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     Preparing learner model with distributed=True\n",
      "10-07-2022 23:44:33 Client-1-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,     0] loss: 0.050\n",
      "10-07-2022 23:44:33 torch.nn.parallel.distributed INFO     Reducer buckets have been rebuilt in this iteration.\n",
      "10-07-2022 23:45:13 Client-1-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,    50] loss: 0.745\n",
      "10-07-2022 23:45:54 Client-1-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,   100] loss: 0.464\n",
      "10-07-2022 23:46:33 Client-1-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,   150] loss: 0.411\n",
      "10-07-2022 23:47:12 Client-1-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,   200] loss: 0.393\n",
      "W1008 01:47:36.315131   34726 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "10-07-2022 23:44:23 root         INFO     Loading file config/configuration.fltk.json\n",
      "10-07-2022 23:44:23 root         INFO     Starting in client mode\n",
      "10-07-2022 23:44:23 root         INFO     Starting with host=trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-master-0 and port=23456\n",
      "10-07-2022 23:44:23 root         INFO     Initializing backend for training process: gloo\n",
      "10-07-2022 23:44:32 torch.distributed.distributed_c10d INFO     Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "10-07-2022 23:44:32 torch.distributed.distributed_c10d INFO     Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "10-07-2022 23:44:32 root         INFO     Starting Creating client with 0\n",
      "10-07-2022 23:44:32 Client-0-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     Initializing learning client\n",
      "10-07-2022 23:44:32 root         INFO     Getting net: Nets.fashion_mnist_cnn\n",
      "10-07-2022 23:44:32 Client-0-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     Preparing learner model with distributed=True\n",
      "10-07-2022 23:44:33 Client-0-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,     0] loss: 0.050\n",
      "10-07-2022 23:44:33 torch.nn.parallel.distributed INFO     Reducer buckets have been rebuilt in this iteration.\n",
      "10-07-2022 23:45:13 Client-0-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,    50] loss: 0.745\n",
      "10-07-2022 23:45:54 Client-0-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,   100] loss: 0.464\n",
      "10-07-2022 23:46:33 Client-0-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,   150] loss: 0.411\n",
      "10-07-2022 23:47:12 Client-0-9afc7e4d-e38a-4f8d-88f4-3d38727842f1 INFO     [1,   200] loss: 0.393\n"
     ]
    }
   ],
   "source": [
    "# To get logs from learners (example)\n",
    "kubectl logs -n test trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-worker-0\n",
    "\n",
    "# To get logs from learners (federated learning)\n",
    "kubectl logs -n test trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1-master-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy experiment results from the extractor\n",
    "\n",
    "Extractor holds the experiment results in the format that can be processedby TensorBoard.\n",
    "In order to download it to the local machine, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 02:10:52.350628   40894 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "W1008 02:10:53.539496   40899 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n"
     ]
    }
   ],
   "source": [
    "EXTRACTOR_POD_NAME=$(kubectl get pods -n test -l \"app.kubernetes.io/name=fltk.extractor\" -o jsonpath=\"{.items[0].metadata.name}\")\n",
    "kubectl cp -n test $EXTRACTOR_POD_NAME:logging ./logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "ls ./logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 02:11:11.374570   40981 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec \"3509c48e84cb9243df6a62abcedcc27e9531f4aa50a1504963adb56d9271de2d\": OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \"curl\": executable file not found in $PATH: unknown\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "kubectl exec -ti -n test pod/$EXTRACTOR_POD_NAME -- curl localhost:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 02:11:20.047576   41016 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.25+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "release \"experiment-orchestrator\" uninstalled\n"
     ]
    }
   ],
   "source": [
    "helm uninstall -n test experiment-orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing extractor\n",
    "\n",
    "IMPORTANT: Removing extractor chart will result in deleting the already collected experiment results, stored in the NFS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 02:11:26.921983   41059 gcp.go:120] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.25+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "release \"extractor\" uninstalled\n"
     ]
    }
   ],
   "source": [
    "helm uninstall extractor -n test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "To scale down the cluster nodepools, run the cell below. This will scale the node pools down and remove all the experiments deployed (on the cluster).\n",
    "\n",
    "1. Experiments cannot be restarted.\n",
    "2. Experiment logs will not persist deletion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1008 02:11:37.373227   41102 gcp.go:119] WARNING: the gcp auth plugin is deprecated in v1.22+, unavailable in v1.26+; use gcloud instead.\n",
      "To learn more, consult https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke\n",
      "pytorchjob.kubeflow.org \"trainjob-023f24a1-ced9-441b-9dcc-ba79452a80ce\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-07a8af2d-d7b1-4d1a-a02e-e59e6e8ab4f2\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-29ea39a2-5748-4ede-8e19-3b326a05c6c1\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-33346b1e-e8b4-437f-a2fb-ee2042d4980f\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-33784eca-66f8-4821-aa27-6c35a401e005\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-366bc88b-f62c-470b-9dd2-d7b272b1398e\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-916ed6ec-1529-4396-b091-197133f02692\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-9afc7e4d-e38a-4f8d-88f4-3d38727842f1\" deleted\n",
      "pytorchjob.kubeflow.org \"trainjob-c72b3b23-6865-4087-a2d4-9d8b9a06a8d7\" deleted\n",
      "Resizing fltk-testbed-cluster...done.                                          \n",
      "Updated [https://container.googleapis.com/v1/projects/eminent-parsec-362007/zones/us-central1-c/clusters/fltk-testbed-cluster].\n",
      "Resizing fltk-testbed-cluster...done.                                          \n",
      "Updated [https://container.googleapis.com/v1/projects/eminent-parsec-362007/zones/us-central1-c/clusters/fltk-testbed-cluster].\n"
     ]
    }
   ],
   "source": [
    "# This will remove all information and logs as well.\n",
    "kubectl delete pytorchjobs.kubeflow.org --all-namespaces --all\n",
    "\n",
    "gcloud container clusters resize $CLUSTER_NAME --node-pool $DEFAULT_POOL \\\n",
    "    --num-nodes 0 --region $REGION --quiet\n",
    "\n",
    "gcloud container clusters resize $CLUSTER_NAME --node-pool $EXPERIMENT_POOL \\\n",
    "    --num-nodes 0 --region $REGION --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "title": "Experiment deployment"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
